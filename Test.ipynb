{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b23dde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='c:\\\\Users\\\\Dalisalar\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='c:\\\\Users\\\\Dalisalar\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from openai import AsyncClient\n",
    "import httpx\n",
    "from cost_estimator import AsyncCostEstimator\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_PROXY = os.getenv(\"OPENAI_PROXY\")\n",
    "\n",
    "client = AsyncClient(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    http_client=httpx.AsyncClient(\n",
    "        proxy=OPENAI_PROXY\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90ade1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate():\n",
    "    r = await client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Привет! Сосчитай 2+2.\"}],\n",
    "        )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2351c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf81f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:_proxy:attr <openai.resources.chat.chat.AsyncChat object at 0x0000022D09F7FDC0>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D078A27D0>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D0A4AB940>\n",
      "DEBUG:_proxy:attr <openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022D09F7F760>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D0A4A85B0>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D0A4A8DC0>\n",
      "DEBUG:_proxy:attr <bound method AsyncCompletions.create of <openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022D09F7F760>>\n",
      "DEBUG:_proxy:attr <function _AsyncClientProxy.__getattr__.<locals>.wrapper at 0x0000022D0A4567A0>\n",
      "DEBUG:_proxy:attr <function _AsyncClientProxy.__getattr__.<locals>.wrapper at 0x0000022D078A5C60>\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d0cf533f-fa85-4bf3-8a63-eaf86e55fa15', 'json_data': {'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}], 'model': 'gpt-4o-mini'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='136.0.196.248' port=63066 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000022D0A4ABDC0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.0', 200, b'Connection established', [])\n",
      "DEBUG:httpcore.proxy:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022D09DEEE40> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.proxy:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000022D09F7EDD0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 16 Aug 2025 10:57:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-dg3luf5kr6eyhxcb2v7srsrd'), (b'openai-processing-ms', b'627'), (b'openai-project', b'proj_tlGOwKOQZdrN8sUMtu8o8kee'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'696'), (b'x-ratelimit-limit-requests', b'30000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'29999'), (b'x-ratelimit-remaining-tokens', b'149999990'), (b'x-ratelimit-reset-requests', b'2ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_edaefe66922a46d386f4a0f79cc38538'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'970069034ffb176c-EWR'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 16 Aug 2025 10:57:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-dg3luf5kr6eyhxcb2v7srsrd', 'openai-processing-ms': '627', 'openai-project': 'proj_tlGOwKOQZdrN8sUMtu8o8kee', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '696', 'x-ratelimit-limit-requests': '30000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '29999', 'x-ratelimit-remaining-tokens': '149999990', 'x-ratelimit-reset-requests': '2ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_edaefe66922a46d386f4a0f79cc38538', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '970069034ffb176c-EWR', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_edaefe66922a46d386f4a0f79cc38538\n",
      "DEBUG:cost_estimator:on_response ChatCompletion(id='chatcmpl-C58t6n1VCtOGm7xUeez3bUK658oU2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 равно 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341840, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))) {'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}]}\n",
      "DEBUG:cost_estimator:model gpt-4o-mini-2024-07-18 in_tok 19 out_tok 12 cached_tok 0 total_tok 31\n",
      "DEBUG:cost_estimator:cost 0.0000100500\n",
      "DEBUG:cost_estimator:on_response ChatCompletion(id='chatcmpl-C58t6n1VCtOGm7xUeez3bUK658oU2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 равно 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341840, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))) {'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}]}\n",
      "DEBUG:cost_estimator:model gpt-4o-mini-2024-07-18 in_tok 19 out_tok 12 cached_tok 0 total_tok 31\n",
      "DEBUG:cost_estimator:cost 0.0000100500\n",
      "DEBUG:cost_estimator:on_response ChatCompletion(id='chatcmpl-C58t6n1VCtOGm7xUeez3bUK658oU2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 равно 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341840, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))) {'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}]}\n",
      "DEBUG:cost_estimator:model gpt-4o-mini-2024-07-18 in_tok 19 out_tok 12 cached_tok 0 total_tok 31\n",
      "DEBUG:cost_estimator:cost 0.0000100500\n",
      "DEBUG:cost_estimator:self.totals Totals(per_model={'gpt-4o-mini': ModelTotals(input_tokens=95, output_tokens=60, cached_tokens=0, total_tokens=155, cost_usd=Decimal('0.0000502500'))})\n",
      "DEBUG:cost_estimator:m ModelTotals(input_tokens=95, output_tokens=60, cached_tokens=0, total_tokens=155, cost_usd=Decimal('0.0000502500'))\n",
      "DEBUG:cost_estimator:self.totals Totals(per_model={'gpt-4o-mini': ModelTotals(input_tokens=57, output_tokens=36, cached_tokens=0, total_tokens=93, cost_usd=Decimal('0.0000301500'))})\n",
      "DEBUG:cost_estimator:m ModelTotals(input_tokens=57, output_tokens=36, cached_tokens=0, total_tokens=93, cost_usd=Decimal('0.0000301500'))\n",
      "DEBUG:cost_estimator:self.totals Totals(per_model={'gpt-4o-mini': ModelTotals(input_tokens=19, output_tokens=12, cached_tokens=0, total_tokens=31, cost_usd=Decimal('0.0000100500'))})\n",
      "DEBUG:cost_estimator:m ModelTotals(input_tokens=19, output_tokens=12, cached_tokens=0, total_tokens=31, cost_usd=Decimal('0.0000100500'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res ChatCompletion(id='chatcmpl-C58t6n1VCtOGm7xUeez3bUK658oU2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 равно 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341840, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "res ChatCompletion(id='chatcmpl-C58t6n1VCtOGm7xUeez3bUK658oU2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 равно 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341840, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "res ChatCompletion(id='chatcmpl-C58t6n1VCtOGm7xUeez3bUK658oU2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 равно 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341840, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:_proxy:attr <openai.resources.chat.chat.AsyncChat object at 0x0000022D09F7FDC0>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D0A4A8F10>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D0A4ABDF0>\n",
      "DEBUG:_proxy:attr <openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022D09F7F760>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D0A4ABB50>\n",
      "DEBUG:_proxy:attr <_proxy._AsyncClientProxy object at 0x0000022D0A4A8640>\n",
      "DEBUG:_proxy:attr <bound method AsyncCompletions.create of <openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022D09F7F760>>\n",
      "DEBUG:_proxy:attr <function _AsyncClientProxy.__getattr__.<locals>.wrapper at 0x0000022D078A5C60>\n",
      "DEBUG:_proxy:attr <function _AsyncClientProxy.__getattr__.<locals>.wrapper at 0x0000022D0A456050>\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ab5badf2-f2ae-4993-9632-e25a30ff969e', 'json_data': {'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}], 'model': 'gpt-4o-mini'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 16 Aug 2025 10:57:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-dg3luf5kr6eyhxcb2v7srsrd'), (b'openai-processing-ms', b'565'), (b'openai-project', b'proj_tlGOwKOQZdrN8sUMtu8o8kee'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'675'), (b'x-ratelimit-limit-requests', b'30000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'29999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'2ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1cf80258e9e340009148ec219df42012'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97006911edca176c-EWR'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 16 Aug 2025 10:57:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-dg3luf5kr6eyhxcb2v7srsrd', 'openai-processing-ms': '565', 'openai-project': 'proj_tlGOwKOQZdrN8sUMtu8o8kee', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '675', 'x-ratelimit-limit-requests': '30000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '29999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '2ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1cf80258e9e340009148ec219df42012', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97006911edca176c-EWR', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_1cf80258e9e340009148ec219df42012\n",
      "DEBUG:cost_estimator:on_response ChatCompletion(id='chatcmpl-C58t81B728I5ZBnSLeQ9hQJnck3Kw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 = 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341842, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))) {'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}]}\n",
      "DEBUG:cost_estimator:model gpt-4o-mini-2024-07-18 in_tok 19 out_tok 12 cached_tok 0 total_tok 31\n",
      "DEBUG:cost_estimator:cost 0.0000100500\n",
      "DEBUG:cost_estimator:on_response ChatCompletion(id='chatcmpl-C58t81B728I5ZBnSLeQ9hQJnck3Kw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 = 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341842, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))) {'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}]}\n",
      "DEBUG:cost_estimator:model gpt-4o-mini-2024-07-18 in_tok 19 out_tok 12 cached_tok 0 total_tok 31\n",
      "DEBUG:cost_estimator:cost 0.0000100500\n",
      "DEBUG:cost_estimator:on_response ChatCompletion(id='chatcmpl-C58t81B728I5ZBnSLeQ9hQJnck3Kw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 = 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341842, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))) {'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Привет! Сосчитай 2+2.'}]}\n",
      "DEBUG:cost_estimator:model gpt-4o-mini-2024-07-18 in_tok 19 out_tok 12 cached_tok 0 total_tok 31\n",
      "DEBUG:cost_estimator:cost 0.0000100500\n",
      "DEBUG:cost_estimator:self.totals Totals(per_model={'gpt-4o-mini': ModelTotals(input_tokens=114, output_tokens=72, cached_tokens=0, total_tokens=186, cost_usd=Decimal('0.0000603000'))})\n",
      "DEBUG:cost_estimator:m ModelTotals(input_tokens=114, output_tokens=72, cached_tokens=0, total_tokens=186, cost_usd=Decimal('0.0000603000'))\n",
      "DEBUG:cost_estimator:self.totals Totals(per_model={'gpt-4o-mini': ModelTotals(input_tokens=76, output_tokens=48, cached_tokens=0, total_tokens=124, cost_usd=Decimal('0.0000402000'))})\n",
      "DEBUG:cost_estimator:m ModelTotals(input_tokens=76, output_tokens=48, cached_tokens=0, total_tokens=124, cost_usd=Decimal('0.0000402000'))\n",
      "DEBUG:cost_estimator:self.totals Totals(per_model={'gpt-4o-mini': ModelTotals(input_tokens=38, output_tokens=24, cached_tokens=0, total_tokens=62, cost_usd=Decimal('0.0000201000'))})\n",
      "DEBUG:cost_estimator:m ModelTotals(input_tokens=38, output_tokens=24, cached_tokens=0, total_tokens=62, cost_usd=Decimal('0.0000201000'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res ChatCompletion(id='chatcmpl-C58t81B728I5ZBnSLeQ9hQJnck3Kw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 = 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341842, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "res ChatCompletion(id='chatcmpl-C58t81B728I5ZBnSLeQ9hQJnck3Kw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 = 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341842, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "res ChatCompletion(id='chatcmpl-C58t81B728I5ZBnSLeQ9hQJnck3Kw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Привет! 2 + 2 = 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755341842, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=12, prompt_tokens=19, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "=== OpenAI Cost Summary ===\n",
      "Total cost: $0.0000201000\n",
      "Tokens: in=38  out=24  cached=0  total=62\n",
      "By model:\n",
      "  - gpt-4o-mini: $0.0000201000  (in=38, out=24, cached=0, total=62)\n",
      "<class '_proxy._AsyncClientProxy'>\n"
     ]
    }
   ],
   "source": [
    "async with AsyncCostEstimator(client) as client:\n",
    "        r = await generate()\n",
    "        await asyncio.sleep(1)\n",
    "        r = await generate()\n",
    "    \n",
    "print(type(client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85290ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
